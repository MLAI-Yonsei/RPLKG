Loading trainer: ZeroshotCLIP
Loading dataset: ImageNet
Loading preprocessed few-shot data from /data/yewon/DATA/imagenet/split_fewshot/shot_16-seed_1.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  16,000
# val      50,000
# test     50,000
---------  --------
/mlainas/KGPrompt_data/imagenet/shot_16_seed_1_train.npy
/mlainas/KGPrompt_data/imagenet/shot_16_seed_1_valid.npy
Loading CLIP (backbone: ViT-B/16)
Loading preprocessed few-shot data from /data/yewon/DATA/imagenet/preprocessed.pkl
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/zs_gumbel_im_test_1/2022-11-19_18-36/imagenet/shots_16/ZeroshotCLIP/vit_b16/seed/tensorboard)
epoch [1/100] batch [5/250] time 0.150 (0.367) data 0.001 (0.001) loss 12.4787 (12.4548) acc 0.0000 (0.3125) lr 1.0000e-05 eta 2:33:02
epoch [1/100] batch [10/250] time 0.150 (0.259) data 0.001 (0.001) loss 12.6622 (12.6121) acc 0.0000 (0.1562) lr 1.0000e-05 eta 1:48:02
epoch [1/100] batch [15/250] time 0.152 (0.223) data 0.001 (0.001) loss 12.1171 (12.3708) acc 0.0000 (0.2083) lr 1.0000e-05 eta 1:33:00
epoch [1/100] batch [20/250] time 0.150 (0.205) data 0.001 (0.001) loss 12.2429 (12.3081) acc 0.0000 (0.1562) lr 1.0000e-05 eta 1:25:27
epoch [1/100] batch [25/250] time 0.151 (0.194) data 0.001 (0.001) loss 11.2085 (12.1626) acc 0.0000 (0.1250) lr 1.0000e-05 eta 1:20:57
epoch [1/100] batch [30/250] time 0.151 (0.187) data 0.001 (0.001) loss 11.8591 (12.1251) acc 0.0000 (0.2083) lr 1.0000e-05 eta 1:17:55
epoch [1/100] batch [35/250] time 0.152 (0.182) data 0.001 (0.001) loss 11.6254 (12.0668) acc 1.5625 (0.2232) lr 1.0000e-05 eta 1:15:47
epoch [1/100] batch [40/250] time 0.153 (0.178) data 0.001 (0.001) loss 10.7407 (11.9321) acc 0.0000 (0.2344) lr 1.0000e-05 eta 1:14:11
epoch [1/100] batch [45/250] time 0.152 (0.175) data 0.001 (0.001) loss 11.5188 (11.8389) acc 0.0000 (0.2083) lr 1.0000e-05 eta 1:12:57
epoch [1/100] batch [50/250] time 0.152 (0.173) data 0.001 (0.001) loss 12.0237 (11.7868) acc 0.0000 (0.2188) lr 1.0000e-05 eta 1:11:57
Traceback (most recent call last):
  File "train.py", line 243, in <module>
    main(args)
  File "train.py", line 175, in main
    trainer.train()
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/dassl/engine/trainer.py", line 478, in train
    super().train(self.start_epoch, self.max_epoch)
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/dassl/engine/trainer.py", line 269, in train
    self.run_epoch()
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/trainers/zsclip.py", line 301, in run_epoch
    loss_summary = self.forward_backward(batch)
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/trainers/zsclip.py", line 402, in forward_backward
    self.model_backward_and_update(loss) #Make sure that CLIP encoder is not trained,, and attention nnLinear is only triained ..
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/dassl/engine/trainer.py", line 321, in model_backward_and_update
    self.model_backward(loss)
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/dassl/engine/trainer.py", line 310, in model_backward
    self.detect_anomaly(loss)
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/dassl/engine/trainer.py", line 241, in detect_anomaly
    if not torch.isfinite(loss).all():
KeyboardInterrupt