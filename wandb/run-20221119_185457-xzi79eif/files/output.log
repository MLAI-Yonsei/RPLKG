Loading trainer: ZeroshotCLIP
Loading dataset: ImageNet
Loading preprocessed few-shot data from /data/yewon/DATA/imagenet/split_fewshot/shot_16-seed_1.pkl
Building transform_train
+ random resized crop (size=(224, 224), scale=(0.08, 1.0))
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
Building transform_test
+ resize the smaller edge to 224
+ 224x224 center crop
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])
---------  --------
Dataset    ImageNet
# classes  1,000
# train_x  16,000
# val      50,000
# test     50,000
---------  --------
/mlainas/KGPrompt_data/imagenet/shot_16_seed_1_train.npy
/mlainas/KGPrompt_data/imagenet/shot_16_seed_1_valid.npy
Loading CLIP (backbone: ViT-B/16)
Loading preprocessed few-shot data from /data/yewon/DATA/imagenet/preprocessed.pkl
Loading evaluator: Classification
No checkpoint found, train from scratch
Initialize tensorboard (log_dir=output/zs_gumbel_im_test_1/2022-11-19_18-54/imagenet/shots_16/ZeroshotCLIP/vit_b16/seed/tensorboard)
epoch [1/100] batch [5/250] time 0.152 (0.373) data 0.001 (0.002) loss 12.4787 (12.4548) acc 0.0000 (0.3125) lr 1.0000e-05 eta 2:35:27
epoch [1/100] batch [10/250] time 0.150 (0.262) data 0.001 (0.001) loss 12.6622 (12.6121) acc 0.0000 (0.1562) lr 1.0000e-05 eta 1:49:09
epoch [1/100] batch [15/250] time 0.151 (0.225) data 0.001 (0.001) loss 12.1171 (12.3708) acc 0.0000 (0.2083) lr 1.0000e-05 eta 1:33:45
epoch [1/100] batch [20/250] time 0.151 (0.207) data 0.001 (0.001) loss 12.2429 (12.3081) acc 0.0000 (0.1562) lr 1.0000e-05 eta 1:25:58
Traceback (most recent call last):
  File "train.py", line 243, in <module>
    main(args)
  File "train.py", line 175, in main
    trainer.train()
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/dassl/engine/trainer.py", line 478, in train
    super().train(self.start_epoch, self.max_epoch)
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/dassl/engine/trainer.py", line 269, in train
    self.run_epoch()
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/trainers/zsclip.py", line 252, in run_epoch
    loss_summary = self.forward_backward(batch)
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/trainers/zsclip.py", line 353, in forward_backward
    self.model_backward_and_update(loss) #Make sure that CLIP encoder is not trained,, and attention nnLinear is only triained ..
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/dassl/engine/trainer.py", line 321, in model_backward_and_update
    self.model_backward(loss)
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/dassl/engine/trainer.py", line 310, in model_backward
    self.detect_anomaly(loss)
  File "/mlainas/yewon/CoOp/CoOp/KGPrompt/dassl/engine/trainer.py", line 241, in detect_anomaly
    if not torch.isfinite(loss).all():
KeyboardInterrupt